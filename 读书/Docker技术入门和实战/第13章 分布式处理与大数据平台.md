分布式系统和大数据处理平台是目前业界关注的热门技术。本章将重点介绍热门的大数 据分布式处理的三大重量级武器： Hadoop、Spark、Storm, 以及新一代的数据采集和分析引 Elasticsearch。

# 13.1 Hadoop

作为当今大数据处理领域的经典分布式平台， Hadoop 要基于 Java 语言实现，由三个核心子系统组成： HDFS 、YARN、MapReduce 其中， HDFS 是一套分布式文件系统； YARN 是资源管理系统， MapReduce 是运行在 YARN 上的应用，负责分布式处理管理。如果从操作系统的角度看， HDFS 相当于 Linux 的 ext3/ext4文件系统， Yam 相当于 Linux 的进程调度和内存分配模块。

Hadoop 的核心子系统说明如下：

- **HDFS**: 一个高度容错性的分布式文件系统，适合部署在大量廉价的机器上，提供高吞吐量的数据访问。
- **YARN** (Yet Another Resource Negotiator) ：资源管理器，可为上层应用提供统一的资源管理和调度，兼容多计算框架。
- **MapReduce**: 是一种分布式编程模型，把对大规模数据集的处理分发 (Map) 给网络 上的多个节点，之后收集处理结果进行规约 (Reduce)。

Hadoop 还包括 HBase （列数据库）、 Cassandra （分布式数据库）、 Hive （支持 SQL 语句）、 Pig （流处理引擎）、 Zookeeper （分布式应用协调服务）等相关项目，其生态系统如图 13-1 所示。

![查看源图像](.\image\13-hadoop生态.jpg)

## 1. 使用官方镜像

```shell
[root@192 ~]# docker pull sequenceiq/hadoop-docker:2.7.0 
```

完成镜像拉取后，使用 docker run 指令运行镜像，同时打开 bash 命令行：

```shell
[root@192 ~]# docker run -it sequenceiq/hadoop-docker:2.7.0 /etc/bootstrap.sh -bash
[root@192 ~]# docker run -it sequenceiq/hadoop-docker:2.7.0 /etc/bootstrap.sh -bash
/
Starting sshd:                                             [  OK  ]
Starting namenodes on [fd004e49f09e]
fd004e49f09e: starting namenode, logging to /usr/local/hadoop/logs/hadoop-root-namenode-fd004e49f09e.out
localhost: starting datanode, logging to /usr/local/hadoop/logs/hadoop-root-datanode-fd004e49f09e.out
Starting secondary namenodes [0.0.0.0]
0.0.0.0: starting secondarynamenode, logging to /usr/local/hadoop/logs/hadoop-root-secondarynamenode-fd004e49f09e.out
starting yarn daemons
starting resourcemanager, logging to /usr/local/hadoop/logs/yarn--resourcemanager-fd004e49f09e.out
localhost: starting nodemanager, logging to /usr/local/hadoop/logs/yarn-root-nodemanager-fd004e49f09e.out
bash-4.1#
```

用户此时可以查看各种配置信息和执行操作，例如查看 namenode 日志等信息：

```shell
bash-4.1# cat /usr/local/hadoop/logs/hadoop-root-namenode-fd004e49f09e.out
ulimit -a for user root
core file size          (blocks, -c) unlimited
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 28957
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1048576
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) unlimited
virtual memory          (kbytes, -v) unlimited
file locks  
```

用户需要验证 Hadoop 环境是否安装成功。首先进入 Hadoop 容器的bash 命令行环境， 进入 Hadoop 目录：

```shell
bash-4.1# cd $HADOOP_PREFIX
bash-4.1# pwd /usr/local/hadoop
```

然后通过运行 Hadoop 内置的实例程序来进行测试：

```shell
bash-4.1# bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.0.jar grep input output  'dfs[a-z.]+'
22/09/10 23:31:41 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
22/09/10 23:31:42 INFO input.FileInputFormat: Total input paths to process : 31
22/09/10 23:31:42 INFO mapreduce.JobSubmitter: number of splits:31
22/09/10 23:31:42 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1662866548895_0002
22/09/10 23:31:42 INFO impl.YarnClientImpl: Submitted application application_1662866548895_0002
22/09/10 23:31:43 INFO mapreduce.Job: The url to track the job: http://fd004e49f09e:8088/proxy/application_1662866548895_0002/
22/09/10 23:31:43 INFO mapreduce.Job: Running job: job_1662866548895_0002
...
```

最后用户可以使用 hdfs 指令检查输出结果：

```shell
bash-4.1# bin/hdfs dfs -cat output/*
6       dfs.audit.logger
4       dfs.class
3       dfs.server.namenode.
2       dfs.period
2       dfs.audit.log.maxfilesize
2       dfs.audit.log.maxbackupindex
1       dfsmetrics.log
1       dfsadmin
1       dfs.servers
1       dfs.replication
1       dfs.file
```

## 2. 相关资源

Hadoop 的相关资源如下：

- Hadoop 官网： http://hadoop.apache.org
- Hadoop 镜像： https://hub.docker.com/r/sequenceiq/hadoop-docker/
- Hadoop 镜像仓库：https://github.com/sequenceiq/hadoop-docker
- Hadoop Dockerfile:  https://hub.docker.corn/r/sequenceiq/hadoop-docker/~/dockerfile/ 

# 13.2 Spark

Apache Spark 是一个围绕速度、易用性和复杂分析构建的大数据处理框架，基于 Scala 开发。最初在 2009 年由加州大学伯克利分校的 AMPLab 开发，并于 2010 年成为 Apache 的开源项目之一。与 Hadoop和Storm 等其他大数据及 MapReduce 技术相比， Spark 支持更灵活的函数定义，可以将应用 处理速度提升 1~2 个数量级，并且提供了众多方便的实用工具，包括 SQL 查询、流处理、 机器学习和图处理等：

Spark 目前支持 Scala、Java、Python、Clojure、R 程序设计语言编写应用。除了 Spark 核心 API 之外， Spark 生态系统中还包括其他附加库，可以在大数据分析和机器学习领域提供更多的能力。这些库包括： Spark Streaming 用于构建弹性容错的流处理 App)，Spark SQL( 支持SQL 语句以及结构化数据处理）， Spark MLlib （用于机器学习）， Spark GraphX （用于图数据处理）。除了这些库以外，还有一些其他的库，如 BlinkDB 和Tachyon

Spark 典型架构包括三个主要组件：驱动程序、集群管理器、工作者节点

![查看源图像](.\image\13-spark-典型架构.jpg)

目前 Spark 推出了 2.2 版本，性能大幅度提升，并在数据流支持方面推出了很多新功能。

## 1. 使用官方镜像

用户可以使用 sequenceiq/spark 镜像，版本方面支持 Hadoop 2.6.0 Apache Sparkvl.6.0  (CentOS) 。同时此镜像还包含 Dockerfile, 用户可以基于它构建自定义的 Apache Spark 镜像。

```shell
[root@localhost ~]# docker pull sequenceiq/spark:1.6.0
```

另外，用户在运行容器时，需要映射 YARN UI 需要的端口：

```shell

[root@localhost ~]# docker run -it -p 8088:8088 -p 8042:8042 -h sandbox sequenceiq/spark:1.6.0 bash
/
Starting sshd:                                             [  OK  ]
Starting namenodes on [sandbox]
sandbox: starting namenode, logging to /usr/local/hadoop/logs/hadoop-root-namenode-sandbox.out
localhost: starting datanode, logging to /usr/local/hadoop/logs/hadoop-root-datanode-sandbox.out
Starting secondary namenodes [0.0.0.0]
0.0.0.0: starting secondarynamenode, logging to /usr/local/hadoop/logs/hadoop-root-secondarynamenode-sandbox.out
starting yarn daemons
starting resourcemanager, logging to /usr/local/hadoop/logs/yarn--resourcemanager-sandbox.out
localhost: starting nodemanager, logging to /usr/local/hadoop/logs/yarn-root-nodemanager-sandbox.out
bash-4.1#
```

启动后，可以使用 bash 命令行来查看 namenode 日志等信息：

```shell
bash-4.1# cat /usr/local/hadoop/logs/hadoop-root-namenode-sandbox.out
ulimit -a for user root
core file size          (blocks, -c) unlimited
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 28957
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1048576
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) unlimited
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
```

用户还可以使用 daemon 模式运行此 Spark 环境：

```shell
[root@localhost ~]# docker run -d -h sandbox sequenceiq/spark:1.6.0 -d
5b3a6bdce80d30a9c617b8885ce3485ce7b48b2702b7ad8b30036c91b7119940
```

继续使用 docker ps 指令查看运行详情：

```shell
[root@localhost ~]# docker ps
CONTAINER ID   IMAGE                            COMMAND                  CREATED              STATUS                 PORTS                                                                                                                                                                                     NAMES
5b3a6bdce80d   sequenceiq/spark:1.6.0           "/etc/bootstrap.sh -d"   About a minute ago   Up About a minute      22/tcp, 8030-8033/tcp, 8040/tcp, 8042/tcp, 8088/tcp, 49707/tcp, 50010/tcp, 50020/tcp, 50070/tcp, 50075/tcp, 50090/tcp                                                                     romantic_almeida
```

## 2. 验证

基千 YARN 部署 Spark 系统时，用户有两种部署方式可选： YARN 客户端模式和 YARN 集群模式。下面将分别论述两种部署方式。

### (1) YARN 客户端模式

(1) YARN 客户端模式中， SparkContext （或称为驱动程序）运行在客户端进程中，主 (master) 应用仅处理来自 YARN 的资源管理请求：

```shell
#运行 spark shell
spark-shell \ 
--master yarn-client \
--driver-memory lg \ 
--executor-memory lg \ 
--executor-cores 1 

#执行以下指令，若返回 1000 则符合预期
scala> sc.parallelize(1 to 1000).count()
...
res3: Long = 1000
```

### (2) YARN 集群模式

在YARN 集群模式中， Spark 驱动程序运行于主应用的进程中，即由 YARN从集群层面 进行管理。下面，以 Pi 值计算为例子，展示两种模式的区别：

Pi 计算 (YARN 集群模式）：

```shell
#执行以下指令，成功后，日志中会新增记录 “Pi is roughly 3.1418" 
#集群模式下用户必须指定 --files 参数，以开启 metrics

spark-submit\
--class org.apache.spark.examples.SparkPi \ 
--files $SPARK_HOME/conf/metrics.properties \ 
--master yarn-cluster \
--driver-memory 1 \ 
--executor-memory 1g \
--executor-cores 1 \
$SPARK_HOME/lib/spark-examples-1.6.0-hadoop2.6.0.ar
```

Pi 计算 (YARN 客户端模式）:

```shell
#执行以下指令，成功后，命令行将显示，'Pi is roughly 3.1418"
spark-submit\
--class org.apache.spark.examples.SparkPi \ 
--master yarn-client \
--driver-memory 1g \ 
--executor-memory 1g \ 
--executor-cores 1 \
$SPARK_HOME/lib/spark-examples-1.6.0-hadoop2.6.0.ar
```

### (3) 容器外访问 Spark

如果用户需要从容器外访问 Spark 环境，则需要设置 YARN_CONF_DIR 环境变最。参见 相关资源部分的 Spark 镜像仓库，即可见 yarn-remote-client 文件夹。此文件夹内置远程访问的配置信息：

```shell
export YARN_CONF_DIR="`pwd` /yarn-remote-client"
```

用户只能使用根用户访问 Docker 的 HDFS 环境。当用户从容器集群外部使用非根用户 访问 Spark 环境时，则需要配置 HADOOP_USER_NAME 环境变量：

```shell
export YARN_CONF_DIR="`pwd` /yarn-remote-client"
```

## 3．相关资源

Spark 的相关资源如下：

- Spark 官网： http://spark.apache.org/
- Spark 官方仓库： https://github.com/apache/spark
- Spark 2.0 更新点： http://spark.apache.org/releases/spark-release-2-0-0.html
- Spark 镜像： https://hub.docker.com/r/sequenceiq/spark/
- Spark 镜像仓库： https://github.com/sequenceiq/docker-spark

# 13.3 Storm







# 13.4 Elasticsearch

Elasticsearch 是基于Lucene 的开源搜索服务（Java实现）。它是分布式、多租户的全文搜索引擎，支持RESTful Web接口。Elasticsearch 支持分布式数据存储和分析查询功能，可以轻松扩展到上百台服务器，同时支持处理PB级结构化或非结构化数据。如果配合Logstash、Kibana等组件，可以快速构建一套日志分析平台。

## 1. 使用官方镜像

可以使用官方镜像，快速运行 Elasticsearch 容器：

```shell
[root@localhost ~]# docker run -d elasticsearch:7.10.1
fed5ebe5604362b2da9f84edff83dc5d93778971193a332030a1923271ef3450
```

也可以在启动时传入一些额外的配置参数：

```shell
[root@localhost ~]# docker run -d elasticsearch:7.10.1 elasticsearch -Des.node.name="TestNode"
cf4d637063ef095e9002372e4c3be81c22807d79b6bdbc11cf2db9c736f9649d
```

目前使用的镜像内含默认配置文件，包含预先定义好的默认配置。如果要使用自定义配 置，可以使用数据卷，挂载自定义配置文件至/usr/share/elasticsearch/config：

```shell
[root@localhost ~]# docker run -d -v "$PWD/config":/usr/share/elasticsearch/config.elasticsearch
```

如果需要数据持久化，可以使用数据卷指令，挂载至/usr/share/elasticsearch/data: 

```shell
[root@localhost ~]# docker run -d -v "$PWD/esdata":/usr/share/elasticsearch/data elasticsearch
```

此镜像会暴露 9200和9300 两个默认的 HTTP 端口，可以通过此端口进行服务访问。 9200 端口是对外提供服务的 API 使用的端口， 9300 端口是内部通信端口，这些通信包括心跳、集群内部信息同步。

如果通过 docker stack deploy 或 docker-compose 使用 Elasticsearch, 则可以参 考以下 stack.yml：

```yaml
version: '3.1'
services:
  elasticsearch:
    image: elasticsearch:7.10.1
    container_name: elasticsearch7.10.1
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx1024m"
    hostname: elasticsearch
    restart: always
    ports:
      - 9200:9200
  kibana:
    image: kibana:7.10.1
    container_name: kibana7.10.1
    environment:
      - elasticsearch.hosts=http://localhost:9200
    hostname: kibana
    depends_on:
      - elasticsearch
    restart: always
    ports:
      - "5601:5601"
```

运行

```shell
# docker stack deploy -c stack.yml elasticsearch 或者 docker-compose -f stack.yml up
docker-compose -f stack.yml up
```

等待初始化完成之后，直接访问

http://192.168.245.129:5601



## 2. apm-server

### (1) 安装apm-server

```shell
[root@192 ~]# docker run -d --user=root --name=apm-server --link elasticsearch7.10.1 -p 8200:8200 elastic/apm-server:7.10.1
910c4de299dda01bb29493cf5078ef1bfa7219b1cb069f4c89d392ff204b2e9f
docker: Error response from daemon: Cannot link to /elasticsearch7.10.1, as it does not belong to the default network.
```

从错误中看，是network链接的不对

```shell
# 先看下要链接容器的network
[root@192 ~]# docker inspect elasticsearch7.10.1
{
  ...
  
  "Networks": {
                "my-elasticsearch_default": {
                    "IPAMConfig": null,
                    "Links": null,
                    "Aliases": [
                        "elasticsearch",
                        "a041afee34db"
                    ],
                    "NetworkID": "d0e6b9f5788c6a671da867dca33e1fc5feb48e72abdf3fcd3a5c5edeecf8a85d",
                    "EndpointID": "03ba212e20f4725fe59054b1375caa34672dac69413d23db9a9d61c2a85dc0a9",
                    "Gateway": "172.19.0.1",
                    "IPAddress": "172.19.0.3",
                    "IPPrefixLen": 16,
                    "IPv6Gateway": "",
                    "GlobalIPv6Address": "",
                    "GlobalIPv6PrefixLen": 0,
                    "MacAddress": "02:42:ac:13:00:03",
                    "DriverOpts": null
                }
            }

  ....
}
```

可以看出es用的network名称是my-elasticsearch_default

```shell
# 查询所有的network
[root@192 ~]# docker network ls
NETWORK ID     NAME                       DRIVER    SCOPE
bf570c7625cd   bridge                     bridge    local
d15b42c27d1c   host                       host      local
d0e6b9f5788c   my-elasticsearch_default   bridge    local
df0e43e146ce   my_mysql_default           bridge    local
894bbcf1e071   none                       null      local

```

```shell
# 使用 --net 指定network
[root@192 ~]# docker run -d --user=root --name=apm-server --link elasticsearch7.10.1 --net my-elasticsearch_default -p 8200:8200 elastic/apm-server:7.10.1


[root@192 ~]# docker ps
CONTAINER ID   IMAGE                       COMMAND                  CREATED         STATUS                 PORTS                                                                                                                                      NAMES
b5a55c697688   elastic/apm-server:7.10.1   "/usr/local/bin/dock…"   5 seconds ago   Up 3 seconds           0.0.0.0:8200->8200/tcp, :::8200->8200/tcp      
```

访问8200端口：http://192.168.245.132:8200/

```json
{
  "build_date": "2020-12-04T22:07:34Z",
  "build_sha": "b7c209e80c4674603447458e62963ed5246b5297",
  "version": "7.10.1"
}
```

如果返回上面内容，说明已经启动成功

然后修改配置文件，使其链接到kibana

```shell

[root@192 ~]# docker exec -it b5a55c697688 /bin/bash
[root@b5a55c697688 apm-server]# ls
LICENSE.txt  NOTICE.txt  README.md  apm-server  apm-server.yml  data  fields.yml  ingest  logs
[root@b5a55c697688 apm-server]# vi apm-server.yml
```

```yaml
 
################################################ APM Server 
# 主要是把注释的kibana打开 
apm-server:
  # Defines the host and port the server is listening on. Use "unix:/path/to.sock" to listen on a unix domain socket.
  #apm服务端对外提供http访问ip,端口 目前apm-server本身不支持集群,可以通过反向代理的服务来实现
  host: "ip:8200"
 
  #允许在kibana中对apm客户端的配置做调整
  kibana:
    # For APM Agent configuration in Kibana, enabled must be true.
    #enabled: false
    enabled: true
 
    # Scheme and port can be left out and will be set to the default (`http` and `5601`).
    # In case you specify an additional path, the scheme is required: `http://localhost:5601/path`.
    # IPv6 addresses should always be defined as: `https://[2001:db8::1]:5601`.
    #host: "localhost:5601"
    #配置对应kibana的访问地址,
    host: "ip:5601"
 
#================================= Template =================================
 
# A template is used to set the mapping in Elasticsearch.
# By default template loading is enabled and the template is loaded.
# These settings can be adjusted to load your own template or overwrite existing ones.
 
# Set to false to disable template loading.
setup.template.enabled: true
 
# Template name. By default the template name is "apm-%{[observer.version]}"
# The template name and pattern has to be set in case the elasticsearch index pattern is modified.
setup.template.name: "apm-%{[observer.version]}"
 
# Template pattern. By default the template pattern is "apm-%{[observer.version]}-*" to apply to the default index settings.
# The first part is the version of apm-server and then -* is used to match all daily indices.
# The template name and pattern has to be set in case the elasticsearch index pattern is modified.
setup.template.pattern: "apm-%{[observer.version]}-*"
 
 
#================================ Outputs =================================
 
# Configure the output to use when sending the data collected by apm-server.
 
#关闭iml策略
setup.ilm.enabled: false
#-------------------------- Elasticsearch output --------------------------
output.elasticsearch:
  # Array of hosts to connect to.
  # Scheme and port can be left out and will be set to the default (`http` and `9200`).
  # In case you specify and additional path, the scheme is required: `http://localhost:9200/path`.
  # IPv6 addresses should always be defined as: `https://[2001:db8::1]:9200`.
  # hosts: ["localhost:9200"]
  hosts: ["http://ip:9200","http://ip:9200"]
  index: "apm-%{[observer.version]}-%{+yyyy.MM.dd}"
 
```

然后重启容器

```shell
[root@192 ~]# docker restart b5a55c697688
```

就可以看到这个监控的服务了

### (2) springBoot服务的配置

引入依赖

```xml
<!--Elastic Agent相关依赖-->
<dependency>
    <groupId>co.elastic.apm</groupId>
    <artifactId>apm-agent-attach</artifactId>
    <version>1.17.0</version>
</dependency>
```

resource目录下增加elasticapm.properties配置文件

```properties
# 配置服务名称
service_name=mall-tiny-apm
# 配置应用所在基础包
application_packages=com.liufei.mall.seed
# 配置APM Server的访问地址
server_urls=http://192.168.245.132:8200
```

然后启动服务。

(3) kibana上查看监控

登录kibana

![image-20220915230400563](.\image\13-es-apm-server-kibana.png)

点击进去，就可以看到各种各样的监控信息数据。如JVM、ERRORS等

## 3. 相关资源

Elasticsearch 的相关资源如下：

- Elasticsearch 官网： https://www.elastic.co/products/elasticsearch/
- Elasticsearch 官方仓库： https://github.com/elastic/elasticsearch
- Elasticsearch 官方镜像： https://huh.docker.com/_/elasticsearch/
- Elasticsearch 官方镜像仓库： https://www.docker.elastic.co/



# 13.5 RabbitMq

RabbitMQ是一个在AMQP（Advanced Message Queuing Protocol ）基础上实现的，可复用的企业消息系统。它可以用于大型软件系统各个模块之间的高效通信，支持高并发，支持可扩展。

详细请参考：[RabbitMQ入门教程（概念，应用场景，安装，使用） - 简书 (jianshu.com)](https://www.jianshu.com/p/dae5bbed39b1)

先搜索下：

```shell
[root@192 ~]# docker search rabbitmq
NAME                                                   DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED
rabbitmq                                               RabbitMQ is an open source multi-protocol me…   4466      [OK]
bitnami/rabbitmq                                       Bitnami Docker Image for RabbitMQ               89                   [OK]
nasqueron/rabbitmqadmin                                RabbitMQ management plugin CLI tool Lightwei…   1                    [OK]
bitnami/rabbitmq-exporter                                                                              1
circleci/rabbitmq-delayed                              https://github.com/circleci/rabbitmq-delayed…   1
rabbitmqoperator/cluster-operator                      The RabbitMQ Cluster Operator Docker Image      1
nasqueron/rabbitmq                                     RabbitMQ wth management, MQTT and STOMP plug…   0                    [OK]
itisfoundation/rabbitmq                                                                                0
rapidfort/rabbitmq                                     RapidFort optimized, hardened image for Rabb…   0
clearlinux/rabbitmq                                    RabbitMQ multi-protocol messaging broker wit…   0
corpusops/rabbitmq                                     https://github.com/corpusops/docker-images/     0
...
```

运行

**需要注意**的是`-p 5672:5672` 解释：-p 外网端口：docker的内部端口 ，你们可以改成自己的外网端口号，我这里映射的外网端口是5672那么程序连接端口就是用5672。15672是web端页面

```shell
[root@192 ~]# docker run -d --hostname my-rabbit --name rabbit -p 15672:15672 -p 5672:5672 rabbitmq
```

查看

```shell
[root@192 ~]# docker ps
CONTAINER ID   IMAGE                     COMMAND                  CREATED         STATUS                    PORTS                                                                                                                                      NAMES
97a078904cf8   rabbitmq                  "docker-entrypoint.s…"   3 seconds ago   Up 2 seconds              4369/tcp, 0.0.0.0:5672->5672/tcp, :::5672->5672/tcp, 5671/tcp, 15691-15692/tcp, 25672/tcp, 0.0.0.0:15672->15672/tcp, :::15672->15672/tcp   rabbit

```

启动web管理页面

```shell
[root@192 ~]# docker exec -it 97a078904cf8 bash
root@mall-rabbit:/# rabbitmq-plugins enable rabbitmq_management
Enabling plugins on node rabbit@mall-rabbit:
rabbitmq_management
The following plugins have been configured:
  rabbitmq_management
  rabbitmq_management_agent
  rabbitmq_prometheus
  rabbitmq_web_dispatch
Applying plugin configuration to rabbit@mall-rabbit...
The following plugins have been enabled:
  rabbitmq_management

started 1 plugins.
root@mall-rabbit:/#
```

此时访问：访问 http://192.168.245.132:15672/，访问web界面，这里的用户名和密码默认都是guest

![image-20220914203215558](.\image\13-5-rabbitmq-web-manager.png)

# 13.6 本章小结

本章介绍了分布式处理与大数据处理领域的典型热门工具，包括Hadoop、Spark、Storm、Elasticsearch 等。这些开源项目的出现，极大地降低了开发者进行分布式处理和数据分析的门槛。 

实际上，摩尔定律的失效，必将导致越来越多的复杂任务必须采用分布式架构进行处理。在新的架构和平台下，如何实现高性能、高可用性，如何让应用容易开发、方便调试都是十分复杂的问题。已有的开源平台项目提供了很好的实现参考，方便用户将更多的精力 放到核心业务的维护上。通过基于容器的部署和使用，极大地简化了对复杂系统的使用和 维护。