作为最流行的容器虚拟化手段， Docker 深度应用了操作系统相关领域的多项底层技术。

最早期版本的 Docker 基于已经相对成熟的 Linux Container (LXC) 技术快速实现。自 0.9 版本起， Docker 逐渐摆脱传统 LXC 的限制，转移到全新设计的 libcontainer 之上，后来 更是以此为基础推出了开放容器运行时支持 runc (https://github.corn/opencontainers/runc) 项目。 2015 月， Docker 公司将 runc 捐赠出来，牵头成立了 Linux 基金会支持的 Open Contain.ers  Initiative (OCI) ，专注于容器技术的运行时规范 (runtime-spec) 和镜像规范 (image-spec) ，试图打造更通用、更开放的容器技术规范。

当然， Docker 容器运行在操作系统上，需要来自操作系统的支持。本章将以容器领域最流行的 Linux 宿主系统为例，介绍 Docker 底层依赖的核心技术：包括 Docker 基本架构、 Linux 操作系统的命名空间 (namespace) 、控制组 (control group)、联合文件系统 (union file  system) 和网络虚拟化支持等。

# 17.1 基本架构

Docker 目前采用了标准的 C/S 架构，包括客户端、服务端两大核心组件，同时通过镜像仓库来存储镜像。客户端和服务端既可以运行在一个机器上，也可通过 socket 或者 RESTful API 来进行通信，如图 17-1 所示。

## 1. 服务端

Docker 服务端一般在宿主主机后台运行， dockerd 作为服务端接受来自客户的请求，并通过 containerd 具体处理与容器相关的请求，包括创建、运行、删除容器等。服务端主要包括四个组件：

- **dockerd:** 为客户端提供 RESTful API, 响应来自客户端的请求，采用模块化的架构， 通过专门的 Engine 模块来分发管理各个来自客户端的任务。可以单独升级；
- **docker-proxy :** dockerd 的子进程， 当需要进行容器端口映射时， docker-proxy 完成网络映射配置；
- **containerd: **是 dockerd 的子进程，提供 gRPC 接口响应来自 dockerd 的请求，对下管理 runC 镜像和容器环境。 可以单独升级；
- **containerd-shim：**containerd 的子进 程，为 runC 容器提供支持，同时作为容器内进程的根进程。

![image-20220917222631102](.\image\17.1-docker基础架构图.png)

runC 是从 Docker 公司开源的 libcontainer 项目演化而来的，目前作为一种具体的开放容器标准实现加入 Open Containers Initiative（OCI）。runC 已经支持了 Linux 系统中容器相关技术栈，同时正在实现对其他操作系统的兼容。用户也可以通过使用 docker-runC 命令来直接使用 OCI 规范的容器。

dockerd 默认监听本地的 unix:///var/run/ docker.sock 套接字，只允许本地的 root 用户或 docker用户组成员访问。可以通过－H 选项来修改监听的方式。例如，让 dockerd 监听本地的 TCP 连接 1234 端口，代码如下：

```shell
# 注意需要先停止docker才能执行下面命令
[root@192 ~]# dockerd -H 127.0.0.1:1234
WARN[2022-09-17T22:34:09.769685791+08:00] [!] DON'T BIND ON ANY IP ADDRESS WITHOUT setting --tlsverify IF YOU DON'T KNOW WHAT YOU'RE DOING [!]
INFO[2022-09-17T22:34:09.776343245+08:00] libcontainerd: started new docker-containerd process  pid=4137
INFO[2022-09-17T22:34:09.776414509+08:00] parsed scheme: "unix"                         module=grpc
...
```

此外， Docker 还支持通过 TLS 认证方式来验证访问。

docker-proxy 只有当启动容器并且使用端口映射时候才会执行，负责配置容器的端口映射规则：

```shell
[root@192 ~]# docker run -itd -p 80:80 ubuntu:latest /bin/sh
28794ffcc7a5e77ec72bb0be29561bd05c0c64c5f6159e7668109bf1c421b62a


[root@192 ~]# ps -ef |grep docker
root       4825   4488  0 22:36 ?        00:00:00 /usr/bin/docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 80 -container-ip 172.17.0.3 -container-port 80

```

## 2. 客户端

Docker 客户端为用户提供一系列可执行命令，使用这些命令可实现与 Docker 服务端 交互。

用户使用的 Docker 可执行命令即为客户端程序。与 Docker 服务端保持运行方式不同， 客户端发送命令后，等待服务端返回；一旦收到返回后，客户端立刻执行结束并退出。用户执行新的命令，需要再次调用客户端命令。

客户端默认通过本地的 unix:///var/run/docker.sock 套接字向服务端发送命令。如果服务端没有监听在默认的地址，则需要客户端在执行命令的时候显式地指定服务端地址。例如， 假定服务端监听在本地的 TCP 连接 1234 端口为 tcp://127.0.0.1 :1234, 只有通过－H 参数指定了正确的地址信息才能连接到服务端：

```shell
[root@192 ~]# docker info
Containers: 3
 Running: 1
 Paused: 0
 Stopped: 2
Images: 7
Server Version: 18.06.3-ce
Storage Driver: overlay2
 Backing Filesystem: xfs
 Supports d_type: true
 Native Overlay Diff: true
Logging Driver: json-file
Cgroup Driver: cgroupfs
Plugins:
 Volume: local
 Network: bridge host macvlan null overlay
 Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog
Swarm: inactive
Runtimes: runc
Default Runtime: runc
Init Binary: docker-init
containerd version: 468a545b9edcd5932818eb9de8e72413e616e86e
runc version: a592beb5bc4c4092b1b1bac971afed27687340c5
init version: fec3683
Security Options:
...

# 也可以通过 -H 指定

[root@192 ~]# docker -H tcp://127.0.0.1:1234 info
```

## 3. 镜像仓库

镜像是使用容器的基础， Docker使用镜像仓库 (Registry) 在大规模场景下存储和分发 Docker 镜像。镜像仓库提供了对不同存储后端的支持，存放镜像文件，并且支持 RESTful API, 接收来自 dockerd 的命令，包括拉取、上传镜像等。

用户从镜像仓库拉取的镜像文件会存储在本地使用；用户同时也可以上传镜像到仓库， 方便其他人获取。使用镜像仓库可以极大地简化镜像管理和分发的流程。镜像仓库目前作为 Docker 分发项目，巳经开源在 Github (https://github.com/docker/distribution) ，目前支持 API 版本为 2.0

# 17.2 命名空间

命名空间 (namespace) Linux 内核的一个强大特性，为容器虚拟化的实现带来极大便利。利用这一特性，每个容器都可以拥有自己单独的命名空间，运行在其中的应用都像是在独立的操作系统环境中一样。命名空间机制保证了容器之间彼此互不影响。

在操作系统中，包括内核、文件系统、网络、进程号 (Process ID, PID) 、用户号 (User ID, UID) 、进程间通信 (InterProcess Communication, IPC) 等资源，所有的资源都是应用进程直接共享的。要想实现虚拟化，除了要实现对内存、 CPU 、网络 IO 、硬盘 IO 、存储空 等的限制外，还要实现文件系统、网络、 PID、UID、IPC 等的相互隔离。前者相对容易实现一些，后者则需要宿主主机系统的深入支持。

随着Linux 系统对于命名空间功能的逐步完善，现在巳经可以实现这些需求，让进程在彼此隔离的命名空间中运行。虽然这些进程仍在共用同一个内核和某些运行时环境 (runtime, 例如一些系统命令和系统库），但是彼此是不可见的，并且认为自己是独占系统的。

Docker 容器每次启动时候，通过调用 func setNamespaces(daemon *Daemon, s *specs.  Spec, c *conta_iner.Container) error 方法来完成对各个命名空间的配置。

## 1. 进程命名空间

Linux 通过进程命名空间管理进程号，对于同一进程（同一个 task_struct) ，在不同的命名空间中，看到的进程号不相同。每个进程命名空间有一套自己的进程号管理方法。进程命 名空间是一个父子关系的结构，子空间中的进程对于父空间是可见的。新 fork 出的一个进程，在父命名空间和子命名空间将分别对应不同的进程号。例如，查看 Docker服务主进程  (dockerd) 的进程号是 3393, 它作为父进程启动了 docker-containerd 进程，进程号为 3398, 代码如下所示：

```shell
[root@192 ~]# ps -ef | grep docker
root       1090      1  0 22:06 ?        00:00:00 /usr/bin/dockerd
root       1271   1090  0 22:06 ?        00:00:00 docker-containerd --config /var/run/docker/containerd/containerd.toml
root       1720   1630  0 22:08 pts/0    00:00:00 grep --color=auto docker

```

新建一个 Ubuntu 容器，执行 sleep 命令。此时， docker-containerd 进程作为父进程，会为每个容器启动一个 docker-containerd-shim 进程，作为该容器内所有进程的根进程：

```shell
[root@192 ~]# docker run --name test -d ubuntu:16.04 sleep 9999 
```

```shell

[root@192 ~]# ps -ef | grep docker
root       1761   1271  0 22:10 ?        00:00:00 docker-containerd-shim -namespace moby -workdir /var/lib/docker/containerd/daemon/io.containerd.runtime.v1.linux/moby/3f2a904402067954d803104fca88cc200c699103d10be1bab2620b1b5d992fc0 -address /var/run/docker/containerd/docker-containerd.sock -containerd-binary /usr/bin/docker-containerd -runtime-root 

```

从宿主机上查看新建容器的进程的父进程，正是 docker-containerd-shim 进程：

```shell

[root@192 ~]# ps -ef | grep sleep
root       1774   1761  0 22:10 ?        00:00:00 sleep 9999

```

而在容器内的进程空间中，则把 docker-containerd-shim 进程作为 0 号根进程（类似宿主系统中0号根进程 idle), while 进程的进程号则变为 1（类似宿主系统中 1 号初始化进程 sbin/init) 。容器内只能看到 docker-containerd-shim进程往下的子进程空间，而无法获知宿主机上的进程信息：

```shell
[root@192 ~]# docker exec -it 3f2a90440206 bash -c 'ps -ef'
UID         PID   PPID  C STIME TTY          TIME CMD
root          1      0  0 14:10 ?        00:00:00 sleep 9999
root          6      0  0 14:14 pts/0    00:00:00 ps -ef
```

通过 pstree 命令，可以直接看到完整的进程树结构：

```shell
# 没有pstree命令，可通过命令安装 yum -y install psmisc
[root@192 ~]# pstree -l -a -A 1271
docker-containe --config /var/run/docker/containerd/containerd.toml
  |-docker-containe -namespace moby -workdir /var/lib/docker/containerd/daemon/io.containerd.runtime.v1.linux/moby/3f2a904402067954d803104fca88cc200c699103d10be1bab2620b1b5d992fc0 -address /var/run/docker/containerd/docker-containerd.sock -containerd-binary /usr/bin/docker-containerd -runtime-root /var/run/docker/runtime-runc
  |   |-sleep 9999
  |   `-9*[{docker-containe}]
  `-8*[{docker-containe}]
```

一般情况下，启动多个容器时，宿主机与容器内进程空间的关系如下图所示。

![image-20220918222840445](.\image\17-2-宿主机与容器内进程空间的关系.png)

## 2. IPC 命令空间

容器中的进程交互还是采用了 Linux 常见的 进程间交互方法 (Interprocess Communication,  IPC) ，包括信号量、消息队列和共享内存等方式。 PID 命名空间和 IPC 命名空间可以组合起来一起使用，同一个 IPC 命名空间内的进程可以彼此可见，允许进行交互；不同空间的进程则无法交互。

## 3. 网络命名空间

有了进程命名空间后，不同命名空间中的进程号可以相互隔离，但是网络端口还是共享本地系统的端口。

通过网络命名空间，可以实现网络隔离。一个网络命名空间为进程提供了一个完全独立的网络协议栈 的视图。包括网络设备接口、 IPv4和IPv6 协议栈、 IP 路由表、防火墙规则、 sockets 等，这样每个容器的网络就能隔离开来。

Docker 采用虚拟网络设备 （Virtual Network Device, VND）的方式，将不同命名空间的网络设备连接到一 起。

默认情况下， Docker 在宿主机上创建多个虚机网桥（如默认的网桥 docker0) ，容器中的虚拟网卡通过网桥进行连接，如下图所示。

![image-20220918230445459](.\image\17-2-3-docker将不同命令空间和网络连接在一起.png)

使用 clocker network ls 命令可以查看到当前系统中的网桥：

```shell
[root@192 ~]# docker network ls
NETWORK ID          NAME                          DRIVER              SCOPE
93cb7b869a77        bridge                        bridge              local
c0b2d32f5675        host                          host                local
402f25e6b9f7        mall-docker-compose_default   bridge              local
96cf43601659        none                          null                local
```

使用 brctl 工具（需要安装 bridge-utils 工具包），还可以看到连接到网桥上的虚拟网口的信息。每个容器默认分配一个网桥上的虚拟网口，并将 docker0 的IP 地址设置为默认的网关，容器发起的网络流量通过宿主机的 iptables 规则进行转发：

```shell
# yum install bridge-utils -y
[root@192 ~]# brctl show
bridge name     bridge id               STP enabled     interfaces
br-402f25e6b9f7         8000.024232f35601       no              vethafbd067
                                                        vethe89f99a
docker0         8000.02420748151e       no

```

## 4. 挂载命名空间

类似于chroot，挂载 (Mount, MNT) 命名空间可以将一个进程的根文件系统限制到一个特定的目录下。

挂载命名空间允许不同命名空间的进程看到的本地文件位于宿主机中不同路径下，每 个命名空间中的进程所看到的文件目录彼此是隔离的。例如，不同命名空间中的进程，都认为自己独占了一个完整的根文件系统 (rootfs) ，但实际上，不同命名空间中的文件彼此隔离， 不会造成相互影响，同时也无法影响宿主机文件系统中的其他路径。

## 5. UTS 命名空间

UTS (UNIX Time-sharing System) 命名空间允许每个容器拥有独立的主机名和域名，从而可以虚拟出一个有独立主机名和网络空间的环境，就跟网络上一台独立的主机一样。

如果没有手动指定主机名称， Docker 容器的主机名就是返回的容器 ID 的前字节前缀， 否则为指定的用户名：

```shell
[root@192 ~]# docker run --name test1 -d ubuntu:16.04 /bin/sh -c "while true;do echo hello world; sleep 1; done"
7c96e37266565ad4d137d8bd006b25ec32b70a9a751f54fc7683a4c07ebe44bd

[root@192 ~]# docker inspect -f {{".Config.Hostname"}} test1
7c96e3726656

[root@192 ~]# docker run --name test2 --hostname test2 -d ubuntu:16.04 /bin/sh -c "while true;do echo hello world; sleep 1; done"
53d49d985c1a1d179f141fad65b0723f98569cb09464030cb94b7b68a1f571c0
[root@192 ~]# docker inspect -f {{".Config.Hostname"}} test2
test2
```

## 6. 用户命名空间

每个容器可以有不同的用户和组 id, 也就是说，可以在容器内使用特定的内部用户执行程序，而非本地系统上存在的用户。

每个容器内部都可以有最高权限的 root 帐号，但跟宿主主机不在一个命名空间。通过使用隔离的用户命名空间，可以提高安全性，避免容器内的进程获取到额外的权限；同时通过使用不同用户也可以进一步在容器内控制权限。

例如，下面的命令在容器内创建了 test 用户，只有普通权限，无法访问更高权限的资源：

```shell
[root@192 ~]# docker run --rm -it ubuntu:16.04 bash
root@59bbb8a63e43:/# cat /proc/1/environ
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/binHOSTNAME=59bbb8a63e43TERM=xtermHOME=/rootroot@59bbb8a63e43:/#
root@59bbb8a63e43:/#
root@59bbb8a63e43:/#
root@59bbb8a63e43:/# useradd -ms /bin/bash test
root@59bbb8a63e43:/# su test
test@59bbb8a63e43:/$ cat /proc/1/environ
cat: /proc/1/environ: Permission denied
```

# 17.3 控制组

控制组 (CGroups) Linux 内核的一个特性，主要用来对共享资源进行隔离、限制、审计等。只有将分配到容器的资源进行控制，才能避免多个容器同时运行时对宿主机系统的资源竞争。每个控制组是一组对资源的限制，支持层级化结构。

控制组技术最早是由 Google 的程序员在 2006 年提出的， Linux 内核自 2.6.24 开始原生支持，可以提供对容器的内存、 CPU 、磁盘 IO 等资源进行限制和计费管理。最初的设计目标是为不同的应用情况提供统一的接口，从控制单一进程（比如 nice 工具）到系统级虚拟化 （包括 OpenVZ, Linux-VServer, LXC 等）。

具体来看，控制组提供如下功能：

- **资源限制 (resource limiting)** ：可将组设置一定的内存限制。比如：内存子系统可以为进程组设定一个内存使用上限，一旦进程组使用的内存达到限额再申请内存，就会 出发 Out of Memory 警告。
- **优先级 (prioritization)** ：通过优先级让一些组优先得到更多的 CPU 等资源。
- **资源审计 (accounting)** ：用来统计系统实际上把多少资源用到适合的目的上，可以使用 cpuacct 子系统记录某个进程组使用的 CPU 时间。
- **隔离 (isolation)** ：为组隔离命名空间，这样使得一个组不会看到另一个组的进程、网络连接和文件系统。
- **控制 (control)** ：执行挂起、恢复和重启动等操作。

Docker 容器每次启动时候，通过调用 func setCapabilities (s *specs. Spec,  c  *container.Container)  error 方法来完成对各个命名空间的配置。安装Docker 后，用户可以在 /sys/fs/cgroup/memory/docker/ 目录下看到对 Docker 组应用的各种限制项， 包括全局限制和位于子目录中对于某个容器的单独限制：

```shell
[root@192 ~]# ls /sys/fs/cgroup/memory/docker
1fdc09a950ee182d33ed9c10bf419dbf970cf5e7d45260b3f5be6ac21d343469  memory.kmem.max_usage_in_bytes      memory.memsw.usage_in_bytes
3b3ba4976af6092a9750e68b5c0613076f3b66d605e45bf36c02457708f14860  memory.kmem.slabinfo                memory.move_charge_at_immigrate
53d49d985c1a1d179f141fad65b0723f98569cb09464030cb94b7b68a1f571c0  memory.kmem.tcp.failcnt             memory.numa_stat
59bbb8a63e433d3021ca822f52f61ed87debe43b5477210703c46c25f7d3afc0  memory.kmem.tcp.limit_in_bytes      memory.oom_control
7c96e37266565ad4d137d8bd006b25ec32b70a9a751f54fc7683a4c07ebe44bd  memory.kmem.tcp.max_usage_in_bytes  memory.pressure_level
cgroup.clone_children                                             memory.kmem.tcp.usage_in_bytes      memory.soft_limit_in_bytes
cgroup.event_control                                              memory.kmem.usage_in_bytes          memory.stat
cgroup.procs                                                      memory.limit_in_bytes               memory.swappiness
memory.failcnt                                                    memory.max_usage_in_bytes           memory.usage_in_bytes
memory.force_empty                                                memory.memsw.failcnt                memory.use_hierarchy
memory.kmem.failcnt                                               memory.memsw.limit_in_bytes         notify_on_release
memory.kmem.limit_in_bytes                                        memory.memsw.max_usage_in_bytes     tasks
```

用户可以通过修改这些文件值来控制组，从而限制 Docker 应用资源。例如，通过下面 的命令可限制 Docker 组中的所有进程使用的物理内存总量不超过 100MB:

```shell
# 默认值：9223372036854771712
[root@192 ~]# echo 104857600 > /sys/fs/cgroup/memory/docke/memory.kmem.limit_in_bytes
```

进入对应的容器文件夹，可以看到对应容器的限制和目前的使用状态：

```shell
[root@192 1fdc09a950ee182d33ed9c10bf419dbf970cf5e7d45260b3f5be6ac21d343469]# ls
cgroup.clone_children  memory.kmem.limit_in_bytes          memory.kmem.tcp.usage_in_bytes  memory.memsw.max_usage_in_bytes  memory.soft_limit_in_bytes  tasks
cgroup.event_control   memory.kmem.max_usage_in_bytes      memory.kmem.usage_in_bytes      memory.memsw.usage_in_bytes      memory.stat
cgroup.procs           memory.kmem.slabinfo                memory.limit_in_bytes           memory.move_charge_at_immigrate  memory.swappiness
memory.failcnt         memory.kmem.tcp.failcnt             memory.max_usage_in_bytes       memory.numa_stat                 memory.usage_in_bytes
memory.force_empty     memory.kmem.tcp.limit_in_bytes      memory.memsw.failcnt            memory.oom_control               memory.use_hierarchy
memory.kmem.failcnt    memory.kmem.tcp.max_usage_in_bytes  memory.memsw.limit_in_bytes     memory.pressure_level            notify_on_release

[root@192 1fdc09a950ee182d33ed9c10bf419dbf970cf5e7d45260b3f5be6ac21d343469]# cat memory.stat
cache 16211968
rss 277889024
rss_huge 12582912
mapped_file 4276224
swap 671744
pgpgin 139794
pgpgout 71058
pgfault 85762
pgmajfault 108
inactive_anon 138960896
active_anon 138928128
inactive_file 7704576
active_file 8507392
unevictable 0
hierarchical_memory_limit 9223372036854771712
hierarchical_memsw_limit 9223372036854771712
total_cache 16211968
total_rss 277889024
total_rss_huge 12582912
total_mapped_file 4276224
total_swap 671744
total_pgpgin 0
total_pgpgout 0
total_pgfault 0
total_pgmajfault 0
total_inactive_anon 138960896
total_active_anon 138928128
total_inactive_file 7704576
total_active_file 8507392
total_unevictable 0
```

同时，可以在创建或启动容器时为每个容器指定资源的限制，例如使用－c|--cpu-shares[=0] 参数可调整容器使用 CPU 的权重；使用－m|--memory[=MEMORY] 参数可调整容器最多使用内存的大小。